from config import *
import numpy as np
import pandas as pd
from pathlib import Path
from utils.features import extract_embeddings
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import joblib

def extract_and_save_features_resnet50(apply_pca=True, pca_var=0.9):
    print("=== Step: Extract ResNet50 Embeddings ===")

    # ====== Load dataset ======
    df_label = pd.read_excel(LABELED_EXCEL)
    all_imgs = [p for p in IMAGES_DIR.glob("*") if p.suffix.lower() in [".jpg", ".jpeg", ".png"]]

    set_label = set(df_label["Filename"].astype(str).str.strip())
    set_all = set(p.stem for p in all_imgs)
    set_unlabel = set_all - set_label

    train_imgs = [p for p in all_imgs if p.stem in set_label]
    test_imgs  = [p for p in all_imgs if p.stem in set_unlabel]

    print(f"âœ… Labeled: {len(train_imgs)} | Unlabeled: {len(test_imgs)}")

    # ====== Extract ResNet50 embeddings ======
    idx_train, X_train = extract_embeddings(train_imgs, backbone_name="resnet50", cache_dir=EMBED_CACHE_DIR)
    idx_test,  X_test  = extract_embeddings(test_imgs,  backbone_name="resnet50", cache_dir=EMBED_CACHE_DIR)

    print(f"[DEBUG] åŸå§‹ç‰¹å¾ç»´åº¦ (ResNet50): {X_train.shape}")

    # ====== Standardization ======
    print("ğŸ”¹ Standardizing features...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled  = scaler.transform(X_test)

    # ====== PCA ======
    if apply_pca:
        print(f"ğŸ”¹ Applying PCA (ä¿ç•™æ–¹å·®æ¯”ä¾‹={pca_var:.2f}) ...")
        pca = PCA(n_components=pca_var, svd_solver='full')
        X_train_pca = pca.fit_transform(X_train_scaled)
        X_test_pca  = pca.transform(X_test_scaled)
        print(f"[INFO] é™ç»´åç»´åº¦: {X_train_pca.shape[1]}")

        # Save PCA features
        out_file = Path(RESULT_DIR) / "resnet50_features_pca.npz"
        np.savez(out_file,
                 X_train=X_train_pca,
                 X_test=X_test_pca,
                 train_filenames=np.array([p.stem for p in train_imgs]),
                 test_filenames=np.array([p.stem for p in test_imgs]))
        print(f"âœ… PCAç‰¹å¾å·²ä¿å­˜: {out_file}")

        # Save models
        joblib.dump(scaler, Path(RESULT_DIR) / "scaler_resnet50.pkl")
        joblib.dump(pca, Path(RESULT_DIR) / "pca_resnet50.pkl")
        print(f"âœ… Scaler ä¸ PCA æ¨¡å‹å·²ä¿å­˜ï¼ˆResNet50ï¼‰")

    else:
        out_file = Path(RESULT_DIR) / "resnet50_features_scaled.npz"
        np.savez(out_file,
                 X_train=X_train_scaled,
                 X_test=X_test_scaled,
                 train_filenames=np.array([p.stem for p in train_imgs]),
                 test_filenames=np.array([p.stem for p in test_imgs]))
        print(f"âœ… æ ‡å‡†åŒ–ç‰¹å¾å·²ä¿å­˜: {out_file}")

if __name__ == "__main__":
    extract_and_save_features_resnet50(apply_pca=True, pca_var=0.9)
