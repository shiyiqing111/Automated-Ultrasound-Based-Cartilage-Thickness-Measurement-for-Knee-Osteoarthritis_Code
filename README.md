# Automated-Ultrasound-Based-Cartilage-Thickness-Measurement-for-Knee-Osteoarthritis
This repository contains a complete workflow for automated measurement of patellofemoral cartilage thickness from clinical ultrasound (US) images. It includes image screening, enhancement, manual keypoint annotation, ResNet-based feature extraction, and regression models (KNN, Linear, RF, XGBoost) for keypoint prediction and thickness calculation. 

## 0. Data & Preprocessing Overview

This section describes the data sources, manual screening steps, image enhancement, and annotation procedures used before model training. These correspond to the key folders and preprocessing Jupyter notebooks in the root directory.

### 0.1 Raw Data

- `Aixplorer_Series/`  
  Original ultrasound dataset stored by examination sequences (exported from the device as DICOM or JPG).  
  This is the starting point of the project. All filtering, enhancement, and annotation steps are based on this directory.  
  Images have been renamed and grouped according to patient ID and examination stage.

- `Book1.xlsx` & `Book2.xlsx`  
  Clinical measurement sheets containing patient IDs, examination laterality/stage, and clinician-measured cartilage thickness.  
  These files are mainly used for reference and alignment. Their structure serves as the basis for renaming and organizing image files.

### 0.2 Filtered & Enhanced Image Directories

- `Aixplorer_Series_FirstFilter/`  
  The first round of filtered sequences.  
  Images that do not contain all three cartilage measurement regions are removed, and the remaining sequences are placed here.  
  This step combines simple rules with manual inspection to reduce the dataset size for later processing.

- `All_images/`  
  The second round of manually filtered images based on `Aixplorer_Series_FirstFilter/`.  
  Only images with acceptable quality and a clearly visible patellofemoral cartilage region are kept for enhancement and modeling.

- `All_enhanced/`  
  Enhanced images generated from `All_images/`.  
  The notebook `Image Enhancement_3.ipynb` tests multiple enhancement combinations (e.g., contrast boosts, denoising, smoothing) and stores the selected enhanced results here for annotation and feature extraction.

- `Labelled_image/`  
  Contains manually annotated images and corresponding JSON files (e.g., from LabelMe).  
  Each JSON file includes six keypoints required for this study, along with optional auxiliary markings.  
  These annotations are parsed and standardized into an Excel sheet in `Label_4.ipynb`.

---

## 1. Preprocessing Notebooks

### 1.1 `Data initialization_1.ipynb`

**Purpose:**  
Initialize and clean data to generate unified indices and tables for all subsequent notebooks.

**Main functions:**

- Read raw examinations from `Aixplorer_Series/` and generate a consolidated table with paths, patient information, and exam stages;  
- Read `Book1.xlsx` / `Book2.xlsx`, align them with image filenames, and produce a matched dataset;  
- Output intermediate tables (e.g., “all image list”, “candidate images for screening/annotation”), providing a unified entry point for later steps.

---

### 1.2 `Integration after initial image screening_2.ipynb`

**Purpose:**  
Integrate “filtered images + annotation results + clinical measurements” into the final master table for model training.

**Main functions:**

- Load the manually filtered image list from `All_images/` or its corresponding Excel;  
- Import the keypoint summary generated by `Label_4.ipynb`;  
- Merge with cartilage thickness measurements in `Book2.xlsx`;  
- Produce the final `annotation_points_summary*.xlsx` files used as inputs for the Model stage.

---

### 1.3 `Image Enhancement_3.ipynb`

**Purpose:**  
Perform image enhancement experiments on filtered images, select the enhancement pipeline, and output enhanced images and quality metrics.

**Main functions:**

- Batch-load images from `All_images/`;  
- Try multiple enhancement methods or parameters (contrast enhancement, denoising, smoothing, etc.) and save results to `All_enhanced/`;  
- Compute and summarize enhancement quality metrics (brightness, contrast, gradients, etc.) into `enhancement_metrics.xlsx` and `enhancement_summary.xlsx`;  
- Assist selection of the final enhancement method through both metrics and visual inspection.

---

### 1.4 `Label_4.ipynb`

**Purpose:**  
Convert JSON annotations in `Labelled_image/` into a standardized keypoint table and perform basic validation.

**Main functions:**

- Batch-read all JSON files in `Labelled_image/`;  
- Extract six keypoint coordinates per image, check ordering, missing values, and anomalies;  
- Export a standardized table (e.g., `annotation_points_summary2.xlsx`) for integration with images and clinical measurements;  
- Optionally visualize keypoints on images for quick manual review.

---

# Model Directory Description

This directory contains all code needed for model training, prediction, and result visualization. The workflow follows the keypoint regression approach described in the project: ResNet feature extraction → regression models → geometric length computation → evaluation.

Directory structure:

---

## 1. Core Scripts

### 1.1 `config.py`

Centralized configuration for:

- Paths to annotation tables (e.g., `merged_annotation.xlsx`, `annotation_points_summary2.xlsx`);  
- Image directories (enhanced or high-quality images);  
- Output paths for `embeddings/`, `predictions/`, and `results/`;  
- Backbone selection (ResNet-18 / ResNet-50) and model list (knn / rf / xgb / linear).

All other scripts read configuration from here.

---

### 1.2 `extract_features_resnet18.py` / `extract_features_resnet50.py`

**Function:** Extract deep features from images and store them in `embeddings/`.

Typical workflow:

1. Load annotation tables and image paths from `config.py`;  
2. Initialize pretrained ResNet-18 or ResNet-50 with the classification head removed;  
3. Forward each image and extract the global average pooling feature vector;  
4. Save outputs to:  
   - `embeddings/resnet18_embeddings.npy` / `resnet50_embeddings.npy`  
   - `embeddings/resnet18_index.xlsx` / `resnet50_index.xlsx` (mapping rows to image names)

These cached features are reused by training scripts.

---

### 1.3 `main_resnet18.py` / `main_resnet50.py`

**Function:** Main training and inference entry script.

Workflow:

1. Load backbone-specific embeddings and index files;  
2. Align features with keypoint labels from `data/merged_annotation.xlsx`;  
3. Apply preprocessing (scaling, PCA) via `utils/features.py`;  
4. Train multiple regressors (KNN / Linear / RF / XGB) from `models/`;  
5. Convert predicted keypoints to three cartilage lengths using `utils/geometry.py`;  
6. Compute MAE, RMSE, R² using `utils/metrics.py` and store summaries in `results/`;  
7. Export predicted coordinates and lengths to `predictions/` for visualization or comparison with Book2.xlsx.

---

### 1.4 `visualize_results.py`

**Function:** Visualization and simple analysis of model outputs.

Examples:

- Read `results/all_models_segment_summary_resnet18.xlsx` / `…resnet50.xlsx`;  
- Plot MAE / RMSE across segments (lateral / central / medial);  
- Generate scatter or Bland–Altman-style plots comparing predictions with clinical measurements;  
- Save plots to `results/comparison/`, `results/resnet18/`, or `results/resnet50/`.

---

## 2. Subdirectory Descriptions

### 2.1 `data/`

Scripts and intermediate tables for annotation merging and clinical evaluation:

- `merge_annotation.py` — unify annotation sources into `merged_annotation.xlsx`;  
- `book_eval.py` — compare predicted vs. clinical thickness values;  
- `io.py` — helper utilities for Excel/CSV reading and writing.

---

### 2.2 `embeddings/`

Stored ResNet feature outputs:

- `resnet18_embeddings.npy` / `resnet50_embeddings.npy` — feature arrays;  
- `resnet18_index.xlsx` / `resnet50_index.xlsx` — row-to-image mappings.

Generated automatically during feature extraction.

---

### 2.3 `models/`

Regression model implementations:

- `knn_model.py`  
- `linear_model.py`  
- `rf_model.py`  
- `xgb_model.py`

Called from `main_resnet18.py` / `main_resnet50.py`.

---

### 2.4 `predictions/`

Contains prediction outputs such as:

- `knn_resnet18_unlabeled_pred.xlsx`  
- `rf_resnet50_unlabeled_pred.xlsx`

Each file typically contains:

- Image name / patient ID  
- Predicted keypoint coordinates  
- Converted cartilage lengths

---

### 2.5 `results/`

Contains aggregated results and intermediate model objects:

- `all_models_segment_summary_resnet18.xlsx` / `…resnet50.xlsx`  
- `pca_resnet18.pkl` / `pca_resnet50.pkl`  
- `scaler_resnet18.pkl` / `scaler_resnet50.pkl`  
- `resnet18_features_pca.npz` / `resnet50_features_pca.npz`  
- Visualization folders: `comparison/`, `resnet18/`, `resnet50/`

---

### 2.6 `utils/`

Utility modules:

- `features.py` — standardization, PCA, and feature preprocessing;  
- `geometry.py` — compute cartilage lengths and pixel-to-cm conversion;  
- `metrics.py` — MAE, RMSE, R², correlations, and summary tables.

Used broadly across training, prediction, and visualization scripts.
