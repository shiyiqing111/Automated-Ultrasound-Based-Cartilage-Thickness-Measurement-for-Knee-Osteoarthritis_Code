# Automated-Ultrasound-Based-Cartilage-Thickness-Measurement-for-Knee-Osteoarthritis
This repository contains a complete workflow for automated measurement of patellofemoral cartilage thickness from clinical ultrasound (US) images. It includes image screening, enhancement, manual keypoint annotation, ResNet-based feature extraction, and regression models (KNN, Linear, RF, XGBoost) for keypoint prediction and thickness calculation. 

## 0. Data & Preprocessing Overview

This section describes the data sources, manual screening steps, image enhancement, and annotation procedures used before model training. These correspond to the key folders and preprocessing Jupyter notebooks in the root directory.

### 0.1 Raw Data

- `Aixplorer_Series/`  
  Original ultrasound dataset stored by examination sequences (exported from the device as DICOM or JPG).  
  This is the starting point of the project. All filtering, enhancement, and annotation steps are based on this directory.  
  Images have been renamed and grouped according to patient ID and examination stage.

- `Book1.xlsx` & `Book2.xlsx`  
  Clinical measurement sheets containing patient IDs, examination laterality/stage, and clinician-measured cartilage thickness.  
  These files are mainly used for reference and alignment. Their structure serves as the basis for renaming and organizing image files.

### 0.2 Filtered & Enhanced Image Directories

- `Aixplorer_Series_FirstFilter/`  
  The first round of filtered sequences.  
  Images that do not contain all three cartilage measurement regions are removed, and the remaining sequences are placed here.  
  This step combines simple rules with manual inspection to reduce the dataset size for later processing.

- `All_images/`  
  The second round of manually filtered images based on `Aixplorer_Series_FirstFilter/`.  
  Only images with acceptable quality and a clearly visible patellofemoral cartilage region are kept for enhancement and modeling.

- `All_enhanced/`  
  Enhanced images generated from `All_images/`.  
  The notebook `Image Enhancement_3.ipynb` tests multiple enhancement combinations (e.g., contrast boosts, denoising, smoothing) and stores the selected enhanced results here for annotation and feature extraction.

- `Labelled_image/`  
  Contains manually annotated images and corresponding JSON files (e.g., from LabelMe).  
  Each JSON file includes six keypoints required for this study, along with optional auxiliary markings.  
  These annotations are parsed and standardized into an Excel sheet in `Label_4.ipynb`.

---

## 1. Preprocessing Notebooks

### 1.1 `Data initialization_1.ipynb`

**Purpose:**  
Initialize and clean data to generate unified indices and tables for all subsequent notebooks.

**Main functions:**

- Read raw examinations from `Aixplorer_Series/` and generate a consolidated table with paths, patient information, and exam stages;  
- Read `Book1.xlsx` / `Book2.xlsx`, align them with image filenames, and produce a matched dataset;  
- Output intermediate tables (e.g., “all image list”, “candidate images for screening/annotation”), providing a unified entry point for later steps.

---

### 1.2 `Integration after initial image screening_2.ipynb`

**Purpose:**  
Integrate “filtered images + annotation results + clinical measurements” into the final master table for model training.

**Main functions:**

- Load the manually filtered image list from `All_images/` or its corresponding Excel;  
- Import the keypoint summary generated by `Label_4.ipynb`;  
- Merge with cartilage thickness measurements in `Book2.xlsx`;  
- Produce the final `annotation_points_summary*.xlsx` files used as inputs for the Model stage.

---

### 1.3 `Image Enhancement_3.ipynb`

**Purpose:**  
Perform image enhancement experiments on filtered images, select the enhancement pipeline, and output enhanced images and quality metrics.

**Main functions:**

- Batch-load images from `All_images/`;  
- Try multiple enhancement methods or parameters (contrast enhancement, denoising, smoothing, etc.) and save results to `All_enhanced/`;  
- Compute and summarize enhancement quality metrics (brightness, contrast, gradients, etc.) into `enhancement_metrics.xlsx` and `enhancement_summary.xlsx`;  
- Assist selection of the final enhancement method through both metrics and visual inspection.

---

### 1.4 `Label_4.ipynb`

**Purpose:**  
Convert JSON annotations in `Labelled_image/` into a standardized keypoint table and perform basic validation.

**Main functions:**

- Batch-read all JSON files in `Labelled_image/`;  
- Extract six keypoint coordinates per image, check ordering, missing values, and anomalies;  
- Export a standardized table (e.g., `annotation_points_summary2.xlsx`) for integration with images and clinical measurements;  
- Optionally visualize keypoints on images for quick manual review.

---

# Model Directory Description

This directory contains all code needed for model training, prediction, and result visualization. The workflow follows the keypoint regression approach described in the project: ResNet feature extraction → regression models → geometric length computation → evaluation.

Directory structure:

---

## 1. Core Scripts

### 1.1 `config.py`

Centralized configuration for:

- Paths to annotation tables (e.g., `merged_annotation.xlsx`, `annotation_points_summary2.xlsx`);  
- Image directories (enhanced or high-quality images);  
- Output paths for `embeddings/`, `predictions/`, and `results/`;  
- Backbone selection (ResNet-18 / ResNet-50) and model list (knn / rf / xgb / linear).

All other scripts read configuration from here.

---

### 1.2 `extract_features_resnet18.py` / `extract_features_resnet50.py`

**Function:** Extract deep features from images and store them in `embeddings/`.

Typical workflow:

1. Load annotation tables and image paths from `config.py`;  
2. Initialize pretrained ResNet-18 or ResNet-50 with the classification head removed;  
3. Forward each image and extract the global average pooling feature vector;  
4. Save outputs to:  
   - `embeddings/resnet18_embeddings.npy` / `resnet50_embeddings.npy`  
   - `embeddings/resnet18_index.xlsx` / `resnet50_index.xlsx` (mapping rows to image names)

These cached features are reused by training scripts.

---

### 1.3 `main_resnet18.py` / `main_resnet50.py`

**Function:** Main training and inference entry script.

Workflow:

1. Load backbone-specific embeddings and index files;  
2. Align features with keypoint labels from `data/merged_annotation.xlsx`;  
3. Apply preprocessing (scaling, PCA) via `utils/features.py`;  
4. Train multiple regressors (KNN / Linear / RF / XGB) from `models/`;  
5. Convert predicted keypoints to three cartilage lengths using `utils/geometry.py`;  
6. Compute MAE, RMSE, R² using `utils/metrics.py` and store summaries in `results/`;  
7. Export predicted coordinates and lengths to `predictions/` for visualization or comparison with Book2.xlsx.

---

### 1.4 `visualize_results.py`

**Function:** Visualization and simple analysis of model outputs.

Examples:

- Read `results/all_models_segment_summary_resnet18.xlsx` / `…resnet50.xlsx`;  
- Plot MAE / RMSE across segments (lateral / central / medial);  
- Generate scatter or Bland–Altman-style plots comparing predictions with clinical measurements;  
- Save plots to `results/comparison/`, `results/resnet18/`, or `results/resnet50/`.

---

## 2. Subdirectory Descriptions

### 2.1 `data/`

Scripts and intermediate tables for annotation merging and clinical evaluation:

- `merge_annotation.py` — unify annotation sources into `merged_annotation.xlsx`;  
- `book_eval.py` — compare predicted vs. clinical thickness values;  
- `io.py` — helper utilities for Excel/CSV reading and writing.

---

### 2.2 `embeddings/`

Stored ResNet feature outputs:

- `resnet18_embeddings.npy` / `resnet50_embeddings.npy` — feature arrays;  
- `resnet18_index.xlsx` / `resnet50_index.xlsx` — row-to-image mappings.

Generated automatically during feature extraction.

---

### 2.3 `models/`

Regression model implementations:

- `knn_model.py`  
- `linear_model.py`  
- `rf_model.py`  
- `xgb_model.py`

Called from `main_resnet18.py` / `main_resnet50.py`.

---

### 2.4 `predictions/`

Contains prediction outputs such as:

- `knn_resnet18_unlabeled_pred.xlsx`  
- `rf_resnet50_unlabeled_pred.xlsx`

Each file typically contains:

- Image name / patient ID  
- Predicted keypoint coordinates  
- Converted cartilage lengths

---

### 2.5 `results/`

Contains aggregated results and intermediate model objects:

- `all_models_segment_summary_resnet18.xlsx` / `…resnet50.xlsx`  
- `pca_resnet18.pkl` / `pca_resnet50.pkl`  
- `scaler_resnet18.pkl` / `scaler_resnet50.pkl`  
- `resnet18_features_pca.npz` / `resnet50_features_pca.npz`  
- Visualization folders: `comparison/`, `resnet18/`, `resnet50/`

---

### 2.6 `utils/`

Utility modules:

- `features.py` — standardization, PCA, and feature preprocessing;  
- `geometry.py` — compute cartilage lengths and pixel-to-cm conversion;  
- `metrics.py` — MAE, RMSE, R², correlations, and summary tables.

Used broadly across training, prediction, and visualization scripts.

---

### 2.7 `optimization/`

This folder contains additional experiments that refine the baseline keypoint–regression pipeline by
directly regressing segment-wise cartilage thickness and enforcing physiologically plausible value
ranges.

Key scripts:

- `seg_length_regression_resnet18_physio.py`  
- `seg_length_regression_resnet50_physio.py`  

**Goal.**  
In the main pipeline, the lateral segment showed substantially worse performance than the femoral
and medial segments: all regressors tended to collapse to an overestimated constant thickness
(~0.6 cm), while the ground-truth lateral thickness in this cohort was typically around
0.1–0.2 cm. This was likely due to the high-dimensional keypoint space and the much larger
absolute scale of the femoral segment. The optimization scripts therefore:

1. Convert the six annotated keypoints into three segment lengths  
   (lateral, femoral, medial) in pixels and then in centimetres using the global
   pixel-to-cm factor;  
2. Train **separate 1D regressors per segment** using the same ResNet-18 / ResNet-50 PCA
   embeddings as inputs;  
3. Apply **physiology-informed clipping** to constrain predictions to literature-based
   cartilage thickness ranges (e.g. ≈0.5–4.0/4.5 mm for femoral trochlear cartilage), so that
   extreme, non-anatomical values (such as lateral thickness > 5 mm) are removed.

Each script trains three model families per segment:

- Ridge regression (`ridge`)  
- Random forest regression (`rf`)  
- Gradient-boosted trees via XGBoost (`xgb`)  

KNN is intentionally not used in this optimization stage, as preliminary tests showed that it was
more sensitive to noise and feature scaling and did not provide consistent benefits over RF/XGBoost
while being more expensive at inference time.

**Inputs and outputs.**

- Inputs:
  - `resnet18_features_pca.npz` / `resnet50_features_pca.npz` (from the main feature-extraction step);  
  - `annotation_points_summary*.xlsx` (for computing segment lengths);  
  - `Book2.xlsx` or its merged version (for clinician-measured reference thickness).  

- Outputs:
  - Per-image predictions with physiologically constrained segment-wise thickness in  
    `predictions/seg_length_models_physio/` (ResNet-18) and  
    `predictions/seg_length_models_physio_resnet50/` (ResNet-50);  
  - Aggregated evaluation tables:
    - `results/segment_length_models_resnet18_physio.xlsx`  
    - `results/segment_length_models_resnet50_physio.xlsx`  
    Each file reports N, MAE, RMSE and R² for every \{segment, model\} combination.

In these experiments, all segments achieve sub-millimetre MAE (≈0.03–0.06 cm), and the lateral
segment improves markedly compared with the original keypoint-regression results, although R²
remains modest, indicating limited captured inter-patient variability.

---

### 3. Additional Visualization for Optimization

- `optimization/visualize_segment_length_physio.py`  

This script reads the physiologically constrained summary tables:

- `results/segment_length_models_resnet18_physio.xlsx`  
- `results/segment_length_models_resnet50_physio.xlsx`

and generates comparison plots for each metric (MAE, RMSE, R²):

- For each model (`ridge`, `rf`, `xgb`), a grouped bar chart showing lateral / femoral / medial
  performance for **ResNet-18 vs ResNet-50**;  
- Plots are saved to:
  - `results/comparison_physio/bars/`

These figures are mainly used in the dissertation to illustrate how segment-wise regression and
physiological range constraints reduce lateral errors and to compare ResNet-18 and ResNet-50
backbones under the optimized setting.

